{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import notebook setup\n",
    "from msc_code.scripts.notebook_setup import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the methods used to collect data from reports, including how many reviewers collected data from each report, whether they worked independently, any processes for obtaining or confirming data from study investigators, and if applicable, details of automation tools used in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import first author (JGE) screened results as pandas dataframe.\n",
    "import_path = os.path.join(PROC_DATA_DIR, \"full_text_screen\", \"jge_included.csv\")\n",
    "jge_included_df = pd.read_csv(import_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Publication Year', 'Authors', 'Title', 'Publication Title',\n",
       "       'Database', 'Exclude', 'Reason ID', 'Paediatric', 'Intention Reported',\n",
       "       'Deliberate intention', 'Unclear', 'Accessed', 'Comments'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jge_included_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe of results to proceed with data extraction whilst second author reviews subset of results.\n",
    "jge_data_extraction_df = jge_included_df[['id', 'Publication Year', 'Authors', 'Title', 'Publication Title']].set_index('id')\n",
    "\n",
    "jge_data_extraction_df.to_csv(\"/\".join([PROC_DATA_DIR, 'data_extraction', 'data_extraction_list.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set import path for data_extraction.xlsx\n",
    "import_path = os.path.join(RAW_DATA_DIR, \"data_extraction\", \"data_extraction.xlsx\")\n",
    "\n",
    "# Import study_data\n",
    "study_data = pd.read_excel(import_path, sheet_name=\"study_data\") # Import study_data\n",
    "patient_data = pd.read_excel(import_path, sheet_name=\"patient_data\") # Import patient_data\n",
    "object_data = pd.read_excel(import_path, sheet_name=\"object_data\") # Import object_data\n",
    "motivation_data = pd.read_excel(import_path, sheet_name=\"motivation_data\") # Import motivation_data\n",
    "intervention_data = pd.read_excel(import_path, sheet_name=\"intervention_data\") # Import motivation_data\n",
    "outcome_data = pd.read_excel(import_path, sheet_name=\"outcome_data\") # Import outcome_data\n",
    "symptom_data = pd.read_excel(import_path, sheet_name=\"symptom_data\") # Import symptom_data\n",
    "complication_data = pd.read_excel(import_path, sheet_name=\"complication_data\") # Import complication_data\n",
    "incidental_findings_data = pd.read_excel(import_path, sheet_name=\"incidental_findings_data\") # Import incidental_findings_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Object Diameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2z/pkyt34z93md62kmcdphb_kf00000gn/T/ipykernel_55353/3396070140.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  object_dimensions.replace(\"Unknown\", np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "if object_data['Object_ID'].duplicated().any():\n",
    "    raise ValueError(\"Duplicate Object_IDs found!\")\n",
    "\n",
    "object_dimensions = object_data[['Object_ID', 'Object_Length_cm', 'Object_Width_cm', 'Object_Height_cm']].set_index('Object_ID')\n",
    "\n",
    "object_dimensions.replace(\"Unknown\", np.nan, inplace=True)\n",
    "object_dimensions = object_dimensions.astype(float)\n",
    "\n",
    "# Compute Object Diameter\n",
    "def compute_diameter(row):\n",
    "    available_values = row.dropna()  # Get non-null values in each row\n",
    "    \n",
    "    if len(available_values) == 1:\n",
    "        return available_values.iloc[0]  # If only one dimension value exists, use it directly to compute object diameter\n",
    "    \n",
    "    elif len(available_values) == 2:\n",
    "        return np.sqrt(sum(available_values**2))  # Use Pythagorean theorem if two values exist\n",
    "    \n",
    "    elif len(available_values) == 3:\n",
    "        return max(available_values)  # If all three exist, take the max\n",
    "    \n",
    "    return np.nan  # If no values exist, return NaN\n",
    "\n",
    "# Apply function row-wise\n",
    "object_dimensions['Object_Diameter_cm'] = object_dimensions.apply(compute_diameter, axis=1)\n",
    "\n",
    "# Create Object Diameter\n",
    "object_dimensions.to_csv(\"/\".join([PROC_DATA_DIR, \"data_extraction\", \"object_dimensions.csv\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate study_data from patient_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate sample size\n",
    "def calculate_sample_size(study_data, patient_data):\n",
    "\n",
    "    # Count occurrences of Study_ID in patient_data\n",
    "    patient_count = patient_data['Study_ID'].value_counts()\n",
    "\n",
    "    # Map counts to study_data where Sample_Size is NaN\n",
    "    study_data['Sample_Size'] = study_data.apply(\n",
    "        lambda row: patient_count.get(row['Study_ID'], row['Sample_Size']) if pd.isna(row['Sample_Size']) else row['Sample_Size'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Ensure integer values\n",
    "    study_data['Sample_Size'] = study_data['Sample_Size'].astype(int)\n",
    "\n",
    "    return study_data\n",
    "\n",
    "study_data = calculate_sample_size(study_data=study_data, patient_data=patient_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2z/pkyt34z93md62kmcdphb_kf00000gn/T/ipykernel_55353/2516665347.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  patient_data['Age_Years'] = patient_data['Age_Years'].replace(\"Unknown\", np.nan)\n"
     ]
    }
   ],
   "source": [
    "# Define Function to calculate Age_Min_Years in study_data with data from patient_data where currently blank\n",
    "def calculate_age_low(study_data, patient_data):\n",
    "\n",
    "    # Replace \"Unknown\" values with NaN\n",
    "    patient_data['Age_Years'] = patient_data['Age_Years'].replace(\"Unknown\", np.nan)\n",
    "\n",
    "    # Compute the minimum Age_Years for each Study_ID\n",
    "    age_min_map = patient_data.groupby(\"Study_ID\")[\"Age_Years\"].min()\n",
    "\n",
    "    # Only fill NaN values in Age_Low_Years\n",
    "    study_data[\"Age_Low_Years\"] = study_data[\"Age_Low_Years\"].fillna(study_data[\"Study_ID\"].map(age_min_map))\n",
    "        \n",
    "    return study_data\n",
    "\n",
    "study_data = calculate_age_low(study_data=study_data, patient_data=patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate Age_Max_Years in study_data with data from patient_data where currently blank\n",
    "def calculate_age_high(study_data, patient_data):\n",
    "\n",
    "    # Replace \"Unknown\" values with NaN\n",
    "    patient_data['Age_Years'] = patient_data['Age_Years'].replace(\"Unknown\", np.nan)\n",
    "\n",
    "    # Compute the maximum Age_Years for each Study_ID\n",
    "    age_max_map = patient_data.groupby(\"Study_ID\")[\"Age_Years\"].max()\n",
    "\n",
    "    # Only fill NaN values in Age_High_Years\n",
    "    study_data[\"Age_High_Years\"] = study_data[\"Age_High_Years\"].fillna(study_data[\"Study_ID\"].map(age_max_map))\n",
    "\n",
    "    return study_data\n",
    "\n",
    "study_data = calculate_age_high(study_data=study_data, patient_data=patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate Age_Mean_Years in study_data with data from patient_data where currently blank \n",
    "def calculate_age_mean(study_data, patient_data):\n",
    "\n",
    "    # Replace \"Unknown\" values with NaN\n",
    "    patient_data['Age_Years'] = patient_data['Age_Years'].replace(\"Unknown\", np.nan)\n",
    "\n",
    "    # Compute the maximum Age_Years for each Study_ID\n",
    "    age_mean_map = patient_data.groupby(\"Study_ID\")[\"Age_Years\"].mean()\n",
    "\n",
    "    # Only fill NaN values in Age_High_Years\n",
    "    study_data[\"Age_Mean_Years\"] = study_data[\"Age_Mean_Years\"].fillna(study_data[\"Study_ID\"].map(age_mean_map))\n",
    "\n",
    "    return study_data\n",
    "\n",
    "study_data = calculate_age_mean(study_data=study_data, patient_data=patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate N_Female\n",
    "def calculate_gender_counts(study_data, patient_data):\n",
    "    # Ensure Gender values are consistent\n",
    "    valid_genders = [\"Male\", \"Female\", \"Unknown\"]\n",
    "    patient_data = patient_data[patient_data[\"Gender\"].isin(valid_genders)]\n",
    "\n",
    "    # Compute gender counts per Study_ID\n",
    "    gender_counts = patient_data.groupby(\"Study_ID\")[\"Gender\"].value_counts().unstack(fill_value=0)\n",
    "\n",
    "    # Ensure all expected columns exist\n",
    "    for gender in valid_genders:\n",
    "        if gender not in gender_counts.columns:\n",
    "            gender_counts[gender] = 0  # Add missing gender columns\n",
    "\n",
    "    # Map gender counts directly to the corresponding columns in study_data\n",
    "    study_data[\"N_Gender_Male\"] = study_data[\"Study_ID\"].map(gender_counts.get(\"Male\", {})).fillna(0).astype(int)\n",
    "    study_data[\"N_Gender_Female\"] = study_data[\"Study_ID\"].map(gender_counts.get(\"Female\", {})).fillna(0).astype(int)\n",
    "    study_data[\"N_Gender_Unknown\"] = study_data[\"Study_ID\"].map(gender_counts.get(\"Unknown\", {})).fillna(0).astype(int)\n",
    "\n",
    "    return study_data\n",
    "\n",
    "# Apply function\n",
    "study_data = calculate_gender_counts(study_data=study_data, patient_data=patient_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate mortality rate in study_data from outcome_data\n",
    "def calculate_mortality_count(study_data, outcome_data):\n",
    "    # Ensure mortality recording is consistent\n",
    "    valid_mortality_outcomes = [\"Yes\", \"No\", \"Unknown\"]\n",
    "    outcome_data = outcome_data[outcome_data[\"Mortality\"].isin(valid_mortality_outcomes)]\n",
    "\n",
    "    # Drop duplicate Patient_ID to ensure each patient is counted only once\n",
    "    unique_mortality = outcome_data.drop_duplicates(subset=\"Patient_ID\")\n",
    "\n",
    "    # Compute mortality counts per Study_ID\n",
    "    mortality_counts = unique_mortality[unique_mortality[\"Mortality\"] == \"Yes\"].groupby(\"Study_ID\")[\"Patient_ID\"].count()\n",
    "\n",
    "    # Map mortality counts to study_data (fill NaN with 0)\n",
    "    study_data[\"Mortality_Count\"] = study_data[\"Study_ID\"].map(mortality_counts).fillna(0).astype(int)\n",
    "\n",
    "    # Replace zeros with NaN to avoid division by zero errors, then compute Mortality Rate\n",
    "    study_data[\"Mortality_Rate\"] = np.where(\n",
    "        study_data[\"Sample_Size\"] > 0, \n",
    "        study_data[\"Mortality_Count\"] / study_data[\"Sample_Size\"], \n",
    "        np.nan  # Set to NaN if division by zero would occur\n",
    "    )\n",
    "\n",
    "    return study_data\n",
    "\n",
    "# Apply function\n",
    "study_data = calculate_mortality_count(study_data=study_data, outcome_data=outcome_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate complication rate\n",
    "def calculate_complication_rate(study_data, complication_data):\n",
    "\n",
    "    pass\n",
    "\n",
    "# study_data = calculate_complication_rate(study_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Export study_Data to CSV\n",
    "study_data.to_csv(\"/\".join([PROC_DATA_DIR, \"data_extraction\", \"study_data.csv\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Gender Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all data\n",
    "study_data.to_csv(\"/\".join([PROC_DATA_DIR, \"data_extraction\", \"study_data.csv\"]))\n",
    "patient_data.to_csv(\"/\".join([PROC_DATA_DIR, \"data_extraction\", \"patient_data.csv\"]))\n",
    "object_data.to_csv(\"/\".join([PROC_DATA_DIR, \"data_extraction\", \"object_data.csv\"]))\n",
    "motivation_data.to_csv(\"/\".join([PROC_DATA_DIR, \"data_extraction\", \"motivation_data.csv\"]))\n",
    "intervention_data.to_csv(\"/\".join([PROC_DATA_DIR, \"data_extraction\", \"intervention_data.csv\"]))\n",
    "outcome_data.to_csv(\"/\".join([PROC_DATA_DIR, \"data_extraction\", \"outcome_data.csv\"]))\n",
    "symptom_data.to_csv(\"/\".join([PROC_DATA_DIR, \"data_extraction\", \"symptom_data.csv\"]))\n",
    "complication_data.to_csv(\"/\".join([PROC_DATA_DIR, \"data_extraction\", \"motivation_data.csv\"]))\n",
    "incidental_findings_data.to_csv(\"/\".join([PROC_DATA_DIR, \"data_extraction\", \"incidental_findings_data.csv\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
