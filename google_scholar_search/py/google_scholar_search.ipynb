{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SerpAPI Google Scholar Search\n",
    "\n",
    "**Author:** Jack Galbraith-Edge\n",
    "\n",
    "**Date:** 8th January 2025\n",
    "\n",
    "## Background\n",
    "Google Scholar is popular tool for searching grey literature. Unlike databases like PubMed and Embase which are curated, maintained by humans and contain only published literature. Google Scholar, on the other hand, searches the internet for what it believes are academic materials and then displays them in a list. As a result, Google Scholar is excellent for seaching grey literature, as results will include unpublished data such as thesises and other useful material, reducing publication bias and susceptability bias (Haddaway et al., 2015)\n",
    "\n",
    "Unfortunately, because Google Scholar references the internet in this way and is not itself a database, this can make querying cumbersome and the number of results returned by queries and be overwhelming. \n",
    "\n",
    "Following the failure of my experiments with Scholarly, I opted to use SerpAPI to query Google Scholar and clean and manipulate the results to add to my systematic review database/literature search. SerpAPI has a free-tier up to 100 Google Scholar requests per month, so I utilise my free trial and give it a go.\n",
    "\n",
    "This document details my search queries and how I've tailored them to gather an appropriate number of results.\n",
    "\n",
    "## Important\n",
    "The result limit in my query function is set to 300. This is because some research exists to researches should focus on the first 200-300 results, with useful res (Haddaway et al., 2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os   # for navigating file system\n",
    "import json # for working with json files\n",
    "from dotenv import load_dotenv  # to load enviromental variables and aid privacy of API keys and similar\n",
    "from serpapi import GoogleSearch    # for querying google scholar\n",
    "import pandas as pd # for working with dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SerpAPI key loaded.\n",
      "OUTPUT_PATH loaded.\n"
     ]
    }
   ],
   "source": [
    "# load environmental variables\n",
    "load_dotenv()\n",
    "\n",
    "# get SerpAPI key from .env file.\n",
    "try: \n",
    "    SERP_API_KEY = os.getenv('SERP_API_KEY')\n",
    "    print(\"SerpAPI key loaded.\")\n",
    "except KeyError:\n",
    "    print(\"SerpAPI Key not found\")\n",
    "\n",
    "# get file output path from .env\n",
    "try:\n",
    "    OUTPUT_PATH = os.getenv('GS_SEARCHES_OUTPUT_PATH')\n",
    "    print(\"OUTPUT_PATH loaded.\")\n",
    "except KeyError:\n",
    "    print(\"Error: OUTPUT_PATH not found in .env file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to query google scholar\n",
    "def query_google_scholar(google_scholar_query, api_key=SERP_API_KEY, max_results=300):\n",
    "\n",
    "    \"\"\"\n",
    "    Query google scholar using SerpAPI\n",
    "    \n",
    "    Parameters: \n",
    "        - google_scholar_query: a string search query\n",
    "        - api_key = SerpAPI key, available at: https://serpapi.com/\n",
    "        - max_results = 300. Set at this level as single author and some evidence says that this is suitable limit.\n",
    "    \"\"\"\n",
    "\n",
    "    all_results = []  # store all results here\n",
    "    start = 0         # start with the first page\n",
    "\n",
    "    while len(all_results) < max_results:\n",
    "        # define parameters for searching google scholar\n",
    "        params = {\n",
    "          \"api_key\": api_key,  # SerpAPI key\n",
    "          \"engine\": \"google_scholar\", # google_scholar engine\n",
    "          \"q\": google_scholar_query, # define query\n",
    "          \"start\": start,\n",
    "          \"num\": 20\n",
    "        }\n",
    "\n",
    "        # search google scholar\n",
    "        search = GoogleSearch(params)\n",
    "        results = search.get_dict() # get results as dictionary\n",
    "\n",
    "        # get organic results\n",
    "        organic_results = results.get(\"organic_results\", []) # retrieve organic list of results from results\n",
    "\n",
    "        # add results to the list\n",
    "        all_results.extend(organic_results)\n",
    "\n",
    "        # check if there are no more results\n",
    "        if len(organic_results) < 20:\n",
    "            print(\"No more results to fetch.\")\n",
    "            break  # exit the loop\n",
    "\n",
    "        # increment parameter for next page\n",
    "        start += 20\n",
    "        print(f\"Fetched {len(all_results)} results so far...\")\n",
    "\n",
    "        if len(all_results) == max_results:\n",
    "            print(f\"Maximum number of {max_results} results reached.\")\n",
    "\n",
    "    return all_results[:max_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scholar_to_df(organic_results, all_results_dict):\n",
    "\n",
    "    \"\"\"\n",
    "    A function to transform dictionary output of SerpAPI Google Scholar Query into a\n",
    "    pandas dataframe.\n",
    "\n",
    "    Requirements:\n",
    "        - Pandas\n",
    "\n",
    "    Usage: \n",
    "        - Takes input from query_google_scholar function.\n",
    "        - Outputs a pandas DataFrame\n",
    "    \"\"\"\n",
    "# convert organic results to dictionary\n",
    "    organic_results_dict = {}\n",
    "\n",
    "    for item in organic_results:\n",
    "        organic_results_dict[len(organic_results_dict)] = item\n",
    "\n",
    "    organic_results_df = pd.DataFrame(columns=[\n",
    "    'Publication Year', 'First Author', 'Summary', 'Authors', 'Publication Title',\n",
    "    'Title', 'Abstract', 'url', 'Database', 'Exclude', 'Reason ID',\n",
    "    'Reason'])\n",
    "\n",
    "    # create empty list to store rows\n",
    "    rows = []\n",
    "\n",
    "    # iterate through organic_results_dict\n",
    "    for item in organic_results_dict.values():\n",
    "        # extract information\n",
    "        title = item.get('title', None)\n",
    "        abstract = item.get('snippet', None)\n",
    "\n",
    "        summary = item['publication_info'].get('summary', \"Summary not found.\")\n",
    "        if summary:\n",
    "            authors = summary.split(' - ')[0].strip() if ' - ' in summary else \"No Author Listed\"\n",
    "            publication_info = summary.split(' - ')[1].strip() if ' - ' in summary else \"No Publication Information\"\n",
    "            publication_title = publication_info.split(',')[0].strip() if ',' in publication_info else None\n",
    "            year = publication_info.split(',')[-1].strip() if ',' in publication_info else None\n",
    "        else:\n",
    "            authors = publication_title = year = None\n",
    "\n",
    "        # add database specific fields\n",
    "        database = \"Google Scholar\"\n",
    "        exclude = None\n",
    "        reason_id = None\n",
    "        reason = None\n",
    "\n",
    "        # append row as dictionary\n",
    "        rows.append({\n",
    "            'Publication Year': year,\n",
    "            'First Author': f\"{authors.split(' ')[-1]}, {authors.split(' ')[0][0]}.\" if authors else None,\n",
    "            'Authors': authors,\n",
    "            'Summary': summary,\n",
    "            'Publication Title': publication_title,\n",
    "            'Title': title,\n",
    "            'Abstract': abstract, \n",
    "            'URL': item.get('link', None),\n",
    "            'Database': database,\n",
    "            'Exclude': exclude,\n",
    "            'Reason ID': reason_id,\n",
    "            'Reason': reason\n",
    "        })\n",
    "\n",
    "    organic_results_df = pd.DataFrame(rows).sort_values(by=\"Publication Year\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    return organic_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to all results dictionary\n",
    "def append_results(query, df, results_dict):\n",
    "\n",
    "    \"\"\"\n",
    "    A function that appends query and the resultant dataframe to a dictionary.\n",
    "    Allows for tracking of queries and for number of results from these queries. \n",
    "    \"\"\"\n",
    "\n",
    "    if results_dict is None:\n",
    "        results_dict = {}\n",
    "\n",
    "    results_dict[len(results_dict)] = {\n",
    "        \"query\": query,\n",
    "        \"results\": df}\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define google scholar query\n",
    "google_scholar_query =  \"\"\"\n",
    "                        (\"foreign obj*\" OR \"foreign bod*\")\n",
    "                        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 20 results so far...\n",
      "Fetched 40 results so far...\n",
      "Fetched 60 results so far...\n",
      "Fetched 80 results so far...\n",
      "Fetched 100 results so far...\n",
      "Fetched 120 results so far...\n",
      "Fetched 140 results so far...\n",
      "Fetched 160 results so far...\n",
      "Fetched 180 results so far...\n",
      "Fetched 200 results so far...\n",
      "Fetched 220 results so far...\n",
      "Fetched 240 results so far...\n",
      "Fetched 260 results so far...\n",
      "Fetched 280 results so far...\n",
      "Maximum number of 300 results reached.\n",
      "Fetched 300 results so far...\n"
     ]
    }
   ],
   "source": [
    "organic_results = query_google_scholar(google_scholar_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_scholar_results_df = scholar_to_df(organic_results, all_results_dict)\n",
    "\n",
    "# append results to final\n",
    "all_results_dict = append_results(google_scholar_query, google_scholar_results_df, all_results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define google scholar query\n",
    "google_scholar_query =  \"\"\"\n",
    "                        (\"foreign obj*\" OR \"foreign bod*\")\n",
    "                        AND\n",
    "                        (\"intent*\" OR \"deliberate*\" OR \"purpose*\" OR \"self-injur*\" OR \"selfharm*\" OR \"self-harm*\")\n",
    "                        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 20 results so far...\n",
      "Fetched 40 results so far...\n",
      "Fetched 60 results so far...\n",
      "Fetched 80 results so far...\n",
      "Fetched 100 results so far...\n",
      "Fetched 120 results so far...\n",
      "Fetched 140 results so far...\n",
      "Fetched 160 results so far...\n",
      "Fetched 180 results so far...\n",
      "Fetched 200 results so far...\n",
      "Fetched 220 results so far...\n",
      "Fetched 240 results so far...\n",
      "Fetched 260 results so far...\n",
      "Fetched 280 results so far...\n",
      "Maximum number of 300 results reached.\n",
      "Fetched 300 results so far...\n"
     ]
    }
   ],
   "source": [
    "# query google scholar\n",
    "organic_results = query_google_scholar(google_scholar_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_scholar_results_df = scholar_to_df(organic_results, all_results_dict)\n",
    "\n",
    "# append results to final\n",
    "all_results_dict = append_results(google_scholar_query, google_scholar_results_df, all_results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define google scholar query\n",
    "google_scholar_query =  \"\"\"\n",
    "                        (\"foreign obj*\" OR \"foreign bod*\")\n",
    "                        AND\n",
    "                        (\"intent*\" OR \"deliberate*\" OR \"purpose*\" OR \"self-injur*\" OR \"selfharm*\" OR \"self-harm*\")\n",
    "                        AND\n",
    "                        (\"ingest*\" OR \"swallow*\")\n",
    "                        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 20 results so far...\n",
      "Fetched 40 results so far...\n",
      "Fetched 60 results so far...\n",
      "Fetched 80 results so far...\n",
      "Fetched 100 results so far...\n",
      "Fetched 120 results so far...\n",
      "No more results to fetch.\n"
     ]
    }
   ],
   "source": [
    "# query google scholar\n",
    "organic_results = query_google_scholar(google_scholar_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_scholar_results_df = scholar_to_df(organic_results, all_results_dict)\n",
    "\n",
    "# append results to final\n",
    "all_results_dict = append_results(google_scholar_query, google_scholar_results_df, all_results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define google scholar query\n",
    "google_scholar_query =  \"\"\"\n",
    "                        (\"foreign obj*\" OR \"foreign bod*\")\n",
    "                        AND\n",
    "                        (\"intent*\" OR \"deliberate*\" OR \"purpose*\" OR \"self-injur*\" OR \"selfharm*\" OR \"self-harm*\")\n",
    "                        AND\n",
    "                        (\"ingest*\" OR \"swallow*\"))\n",
    "                        AND\n",
    "                        (\"surg*\" OR \"endoscop*\" OR \"EGD\" OR \"OGD\" OR \"Esophagogastroduodenoscopy\" OR \"Oesophagogastroduodenoscopy\" OR \"manag*\")\"\n",
    "                        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 20 results so far...\n",
      "Fetched 40 results so far...\n",
      "Fetched 60 results so far...\n",
      "No more results to fetch.\n"
     ]
    }
   ],
   "source": [
    "# query google scholar\n",
    "organic_results = query_google_scholar(google_scholar_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_scholar_results_df = scholar_to_df(organic_results, all_results_dict)\n",
    "\n",
    "# append results to final\n",
    "all_results_dict = append_results(google_scholar_query, google_scholar_results_df, all_results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Num Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n                        (\"foreign obj*\" OR \"...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n                        (\"foreign obj*\" OR \"...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n                        (\"foreign obj*\" OR \"...</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n                        (\"foreign obj*\" OR \"...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Query  Num Results\n",
       "0  \\n                        (\"foreign obj*\" OR \"...          300\n",
       "1  \\n                        (\"foreign obj*\" OR \"...          300\n",
       "2  \\n                        (\"foreign obj*\" OR \"...          134\n",
       "3  \\n                        (\"foreign obj*\" OR \"...           60"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show number of results for each query and store in dataframe\n",
    "\n",
    "# create results dataframe\n",
    "results_df = pd.DataFrame(columns=[\"Query\", \"Num Results\"])\n",
    "\n",
    "# initialise list to store rows in \n",
    "rows = []\n",
    "\n",
    "# iterate through all_results_dict that contains queries and results dataframes from query\n",
    "for item in all_results_dict.values():\n",
    "    \n",
    "    query = item.get('query') # get query\n",
    "    num_results = len(item.get('results')) # get number of results - max is 300.\n",
    "\n",
    "    # append row as dictionary\n",
    "    rows.append({\n",
    "        \"Query\": query,\n",
    "        \"Num Results\": num_results\n",
    "        })\n",
    "\n",
    "# create dataframe from rows\n",
    "results_df = pd.DataFrame(rows)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_results_to_csv(results, output_path):\n",
    "    \"\"\"\n",
    "    Function that exports dataframes from queries to CSV.\n",
    "\n",
    "    Parameters:\n",
    "        - Results dictionary\n",
    "    \"\"\"\n",
    "    # check results are in dictionary format\n",
    "    if not isinstance(results, dict):\n",
    "        raise TypeError(f\"Expected a dictionary, but got {type(result).__name__} instead.\")\n",
    "\n",
    "    # export results to csv to inspect\n",
    "    for n, value in enumerate(results.values()):\n",
    "        df = value['results']\n",
    "        output_file = f\"{output_path}/google_scholar_results_{n}.csv\"\n",
    "        df.to_csv(output_file, index=False)\n",
    "\n",
    "all_results_to_csv(all_results_dict, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_csv(results, output_path):\n",
    "    \"\"\"\n",
    "    Export query and query counts to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        - results: A pandas DataFrame.\n",
    "        - output_path: A string representing the output file path (including the file name).\n",
    "    \"\"\"\n",
    "    # Check that results is a pandas dataframe\n",
    "    if not isinstance(results, pd.DataFrame):\n",
    "        raise TypeError(f\"Expected a DataFrame, but got {type(results).__name__} instead.\")\n",
    "    \n",
    "    # strip out \\n from all cells in the dataframe\n",
    "    results = results.apply(lambda col: col.map(lambda x: x.replace('\\n', '') if isinstance(x, str) else x))\n",
    "    \n",
    "    output_file = f\"{output_path}/google_query_results_counts.csv\"\n",
    "\n",
    "    # Save the DataFrame to CSV\n",
    "    results.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export queries and associated results count to review with supervisor.\n",
    "results_to_csv(results_df, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "1.\tHaddaway NR, Collins AM, Coughlin D, Kirk S. The Role of Google Scholar in Evidence Reviews and Its Applicability to Grey Literature Searching. Wray KB, editor. PLoS ONE. 2015 Sep 17;10(9):e0138237. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
