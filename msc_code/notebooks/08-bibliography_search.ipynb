{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "9c1508f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliography Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "14afbb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup notebook\n",
    "from msc_code.scripts.notebook_setup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "80825fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join(RAW_DATA_DIR, 'bibliography_search')\n",
    "output_path = os.path.join(PROC_DATA_DIR, 'bibliography_search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "456a561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import included studies\n",
    "import_path = os.path.join(PROC_DATA_DIR, 'full_text_screen', 'full_text_screen_end_final.csv')\n",
    "ft_data = pd.read_csv(import_path)\n",
    "included_ids = list(ft_data[ft_data['Exclude_FINAL'] == False]['Study_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "68bed96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for bibliography search\n",
    "bib_search_df = pd.DataFrame(columns=['Study_ID', 'Bib_Search_Complete'])\n",
    "\n",
    "bib_search_df['Study_ID'] = included_ids\n",
    "\n",
    "file_path = os.path.join(output_path, 'bib_search_start.csv')\n",
    "bib_search_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "512e0928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reimport data from bibliography search\n",
    "file_path = os.path.join(input_path, 'bib_search_end.xlsx')\n",
    "bib_search_df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "0322dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out excluded papers\n",
    "bib_search_df = bib_search_df[bib_search_df['Study_ID'].isin(included_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "759876f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bib_search_df['Bib_Search_Complete'] = bib_search_df['Bib_Search_Complete'].astype(str)\n",
    "\n",
    "status_map = {\n",
    "    'nan': 'Awaiting Search',\n",
    "    'Y': 'Search Complete',\n",
    "    'N': 'For second review'\n",
    "}\n",
    "\n",
    "bib_search_df['Bib_Search_Complete'] = bib_search_df['Bib_Search_Complete'].map(status_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "id": "408581c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bib_Search_Complete\n",
       "Search Complete    96\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bib_search_df['Bib_Search_Complete'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "5a2af7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import bibliography search results\n",
    "import_path = os.path.join(input_path, 'bib_search_results.csv')\n",
    "bib_search_df = pd.read_csv(import_path)\n",
    "\n",
    "# Sort Results by Publication Year, Author, Title ascending.\n",
    "bib_search_df = bib_search_df.sort_values(by=['Publication Year', 'Author', 'Title'], ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Import initial results to\n",
    "import_path = os.path.join(PROC_DATA_DIR, \"title_abstract_review\", \"all_results_title_abstract_start.csv\")\n",
    "ta_start = pd.read_csv(import_path)\n",
    "\n",
    "# Rename id column\n",
    "ta_start = ta_start.rename(columns={\n",
    "    'id': 'Study_ID'\n",
    "})\n",
    "\n",
    "# Find max study ID\n",
    "starting_index = ta_start['Study_ID'].max() + 1\n",
    "\n",
    "# Create Study_ID for items in bibliography search\n",
    "bib_search_df['Study_ID'] = range(starting_index, starting_index + len(bib_search_df))\n",
    "\n",
    "# Export to CSV\n",
    "file_path = os.path.join(output_path, 'bib_search_results.csv')\n",
    "bib_search_df.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "13c3c988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204 items in bib_search_results before duplicate removal\n",
      "192 items in bib_search_results after duplicate removal\n",
      "192 items in bib_search_results before full-text exclusions\n",
      "192 items in bib_search_results after full-text exclusions\n",
      "Pre-screen exclusions exported.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --- Load title/abstract review ---\n",
    "ta_path = os.path.join(PROC_DATA_DIR, 'title_abstract_review', 'title_abstract_review_FINAL.csv')\n",
    "ta_review = pd.read_csv(ta_path)\n",
    "\n",
    "# --- Load full-text screen ---\n",
    "ft_path = os.path.join(PROC_DATA_DIR, 'full_text_screen', 'full_text_screen_end_final.csv')\n",
    "ft_review = pd.read_csv(ft_path)\n",
    "\n",
    "# --- Normalize helper ---\n",
    "def clean_text(s):\n",
    "    return str(s).strip().lower() if pd.notnull(s) else ''\n",
    "\n",
    "# --- Normalize Titles and DOIs ---\n",
    "bib_search_df['Title_clean'] = bib_search_df['Title'].apply(clean_text)\n",
    "bib_search_df['DOI_clean'] = bib_search_df['DOI'].apply(clean_text)\n",
    "\n",
    "ta_review['Title_clean'] = ta_review['Title'].apply(clean_text)\n",
    "ta_review['DOI_clean'] = ta_review['DOI'].apply(clean_text)\n",
    "\n",
    "# --- Step 1: Original count ---\n",
    "print(f'{len(bib_search_df)} items in bib_search_results before duplicate removal')\n",
    "\n",
    "# --- Step 2: Find duplicates\n",
    "# Match by DOI (if DOI exists and isn't blank)\n",
    "doi_matches = bib_search_df[\n",
    "    (bib_search_df['DOI_clean'] != '') &\n",
    "    bib_search_df['DOI_clean'].isin(\n",
    "        ta_review['DOI_clean'].dropna().loc[lambda x: x != '']\n",
    "    )\n",
    "]\n",
    "\n",
    "# Match by Title only where DOI is missing\n",
    "title_matches = bib_search_df[\n",
    "    (bib_search_df['DOI_clean'] == '') &\n",
    "    bib_search_df['Title_clean'].isin(\n",
    "        ta_review['Title_clean'].dropna().str.strip().str.lower()\n",
    "    )\n",
    "]\n",
    "\n",
    "duplicates = pd.concat([doi_matches, title_matches]).drop_duplicates()\n",
    "\n",
    "# --- Step 3: Remove duplicates from bib_search_df ---\n",
    "duplicate_ids = duplicates['Study_ID'].tolist()\n",
    "bib_search_df = bib_search_df[~bib_search_df['Study_ID'].isin(duplicate_ids)]\n",
    "\n",
    "print(f'{len(bib_search_df)} items in bib_search_results after duplicate removal')\n",
    "\n",
    "# --- Step 4: Prepare full-text exclusions ---\n",
    "ta_review = ta_review.rename(columns={'id': 'Study_ID'})  # if needed\n",
    "\n",
    "ft_review = pd.merge(\n",
    "    ft_review,\n",
    "    ta_review[['Study_ID', 'DOI_clean']],\n",
    "    how='left',\n",
    "    on='Study_ID'\n",
    ")\n",
    "\n",
    "# Mark excluded full-text articles\n",
    "ft_excluded = ft_review[ft_review['Exclude_FINAL'] == True]\n",
    "\n",
    "# --- Step 5: Exclude based on clean DOI ---\n",
    "ft_excluded_dois = ft_excluded['DOI_clean'].dropna().loc[lambda x: x != ''].unique()\n",
    "\n",
    "exclusions = bib_search_df[\n",
    "    (bib_search_df['DOI_clean'] != '') &\n",
    "    bib_search_df['DOI_clean'].isin(ft_excluded_dois)\n",
    "]\n",
    "\n",
    "print(f\"{len(bib_search_df)} items in bib_search_results before full-text exclusions\")\n",
    "bib_search_df = bib_search_df[~bib_search_df['Study_ID'].isin(exclusions['Study_ID'])]\n",
    "print(f\"{len(bib_search_df)} items in bib_search_results after full-text exclusions\")\n",
    "\n",
    "# --- Step 6: Combine pre-screen exclusions ---\n",
    "pre_screen_exclusions = pd.concat([duplicates, exclusions]).drop_duplicates()\n",
    "\n",
    "# --- Step 7: Export results ---\n",
    "# Debug output to audit dropped papers\n",
    "duplicates_out = os.path.join(output_path, 'debug_duplicates_found.csv')\n",
    "duplicates.to_csv(duplicates_out, index=False)\n",
    "\n",
    "# Final pre-screen exclusion list\n",
    "export_path = os.path.join(output_path, 'pre_screen_exclusions.csv')\n",
    "pre_screen_exclusions.to_csv(export_path, index=False)\n",
    "\n",
    "print(\"Pre-screen exclusions exported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "61cd6087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study_ID</th>\n",
       "      <th>Publication Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Publication Title</th>\n",
       "      <th>Database</th>\n",
       "      <th>Exclude</th>\n",
       "      <th>Reason ID</th>\n",
       "      <th>Paediatric</th>\n",
       "      <th>Intention Reported</th>\n",
       "      <th>Deliberate intention</th>\n",
       "      <th>Unclear</th>\n",
       "      <th>Accessed</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>492</td>\n",
       "      <td>1941</td>\n",
       "      <td>Macmanus, Joseph E.</td>\n",
       "      <td>Perforations of the intestine by ingested fore...</td>\n",
       "      <td>The American Journal of Surgery</td>\n",
       "      <td>Bibliography Search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-04-14 17:11:45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>493</td>\n",
       "      <td>1962</td>\n",
       "      <td>Perelman, H.</td>\n",
       "      <td>Toothpick perforations of the gastrointestinal...</td>\n",
       "      <td>The Journal of Abdominal Surgery</td>\n",
       "      <td>Bibliography Search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>494</td>\n",
       "      <td>1967</td>\n",
       "      <td>Sloop, R. D.; Thompson, J. C.</td>\n",
       "      <td>Aorto-esophageal fistula: report of a case and...</td>\n",
       "      <td>Gastroenterology</td>\n",
       "      <td>Bibliography Search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>495</td>\n",
       "      <td>1969</td>\n",
       "      <td>Johnson, Wilbur E.</td>\n",
       "      <td>On Ingestion of Razor Blades</td>\n",
       "      <td>JAMA</td>\n",
       "      <td>Bibliography Search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-04-14 14:35:26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>496</td>\n",
       "      <td>1969</td>\n",
       "      <td>Schechter, D. C.; Gilbert, L.</td>\n",
       "      <td>Injuries of the heart and great vessels due to...</td>\n",
       "      <td>Thorax</td>\n",
       "      <td>Bibliography Search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>691</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Song, Young S; Covarrubias, Diego A; Nardi, Pe...</td>\n",
       "      <td>Foreign Body Appendicitis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bibliography Search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>692</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Endoscopic Retrieval of an Intentionally Inges...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bibliography Search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-04-14 13:57:27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>693</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Escalating Ingestion of Razor Blades in a Pati...</td>\n",
       "      <td>Psychiatrist.com</td>\n",
       "      <td>Bibliography Search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-04-14 14:34:37</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>694</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frequent Deliberate Self-Harm: Repetition, Sui...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bibliography Search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-03-12 15:31:06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>695</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Journey of a Swallowed Toothbrush to the Colon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bibliography Search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-04-14 14:10:47</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Study_ID  Publication Year  \\\n",
       "0         492              1941   \n",
       "1         493              1962   \n",
       "2         494              1967   \n",
       "3         495              1969   \n",
       "4         496              1969   \n",
       "..        ...               ...   \n",
       "199       691              <NA>   \n",
       "200       692              <NA>   \n",
       "201       693              <NA>   \n",
       "202       694              <NA>   \n",
       "203       695              <NA>   \n",
       "\n",
       "                                                Author  \\\n",
       "0                                  Macmanus, Joseph E.   \n",
       "1                                         Perelman, H.   \n",
       "2                        Sloop, R. D.; Thompson, J. C.   \n",
       "3                                   Johnson, Wilbur E.   \n",
       "4                        Schechter, D. C.; Gilbert, L.   \n",
       "..                                                 ...   \n",
       "199  Song, Young S; Covarrubias, Diego A; Nardi, Pe...   \n",
       "200                                                NaN   \n",
       "201                                                NaN   \n",
       "202                                                NaN   \n",
       "203                                                NaN   \n",
       "\n",
       "                                                 Title  \\\n",
       "0    Perforations of the intestine by ingested fore...   \n",
       "1    Toothpick perforations of the gastrointestinal...   \n",
       "2    Aorto-esophageal fistula: report of a case and...   \n",
       "3                         On Ingestion of Razor Blades   \n",
       "4    Injuries of the heart and great vessels due to...   \n",
       "..                                                 ...   \n",
       "199                          Foreign Body Appendicitis   \n",
       "200  Endoscopic Retrieval of an Intentionally Inges...   \n",
       "201  Escalating Ingestion of Razor Blades in a Pati...   \n",
       "202  Frequent Deliberate Self-Harm: Repetition, Sui...   \n",
       "203     Journey of a Swallowed Toothbrush to the Colon   \n",
       "\n",
       "                    Publication Title             Database Exclude Reason ID  \\\n",
       "0     The American Journal of Surgery  Bibliography Search     NaN       NaN   \n",
       "1    The Journal of Abdominal Surgery  Bibliography Search     NaN       NaN   \n",
       "2                    Gastroenterology  Bibliography Search     NaN       NaN   \n",
       "3                                JAMA  Bibliography Search     NaN       NaN   \n",
       "4                              Thorax  Bibliography Search     NaN       NaN   \n",
       "..                                ...                  ...     ...       ...   \n",
       "199                               NaN  Bibliography Search     NaN       NaN   \n",
       "200                               NaN  Bibliography Search     NaN       NaN   \n",
       "201                  Psychiatrist.com  Bibliography Search     NaN       NaN   \n",
       "202                               NaN  Bibliography Search     NaN       NaN   \n",
       "203                               NaN  Bibliography Search     NaN       NaN   \n",
       "\n",
       "    Paediatric Intention Reported Deliberate intention Unclear  \\\n",
       "0          NaN                NaN                  NaN     NaN   \n",
       "1          NaN                NaN                  NaN     NaN   \n",
       "2          NaN                NaN                  NaN     NaN   \n",
       "3          NaN                NaN                  NaN     NaN   \n",
       "4          NaN                NaN                  NaN     NaN   \n",
       "..         ...                ...                  ...     ...   \n",
       "199        NaN                NaN                  NaN     NaN   \n",
       "200        NaN                NaN                  NaN     NaN   \n",
       "201        NaN                NaN                  NaN     NaN   \n",
       "202        NaN                NaN                  NaN     NaN   \n",
       "203        NaN                NaN                  NaN     NaN   \n",
       "\n",
       "                Accessed Comments  \n",
       "0    2025-04-14 17:11:45      NaN  \n",
       "1                    NaN      NaN  \n",
       "2                    NaN      NaN  \n",
       "3    2025-04-14 14:35:26      NaN  \n",
       "4                    NaN      NaN  \n",
       "..                   ...      ...  \n",
       "199                  NaN      NaN  \n",
       "200  2025-04-14 13:57:27      NaN  \n",
       "201  2025-04-14 14:34:37      NaN  \n",
       "202  2025-03-12 15:31:06      NaN  \n",
       "203  2025-04-14 14:10:47      NaN  \n",
       "\n",
       "[192 rows x 14 columns]"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename to match screening format\n",
    "bib_search_df = bib_search_df.rename(columns={\n",
    "    'Access Date': 'Accessed'\n",
    "})\n",
    "\n",
    "# Define the screening columns\n",
    "screening_columns = [\n",
    "    'Study_ID', 'Publication Year', 'Author', 'Title',\n",
    "    'Publication Title', 'Database', 'Exclude', 'Reason ID',\n",
    "    'Paediatric', 'Intention Reported', 'Deliberate intention',\n",
    "    'Unclear', 'Accessed', 'Comments'\n",
    "]\n",
    "\n",
    "# Create empty screening DataFrame with same index as bib_search_df\n",
    "bib_search_screening = pd.DataFrame(index=bib_search_df.index, columns=screening_columns)\n",
    "\n",
    "# Fill in matching columns from bib_search_df\n",
    "for col in screening_columns:\n",
    "    if col in bib_search_df.columns:\n",
    "        bib_search_screening[col] = bib_search_df[col]\n",
    "\n",
    "# Set the Database source\n",
    "bib_search_screening['Database'] = \"Bibliography Search\"\n",
    "\n",
    "# Safely convert numeric fields with missing values allowed\n",
    "bib_search_screening['Publication Year'] = pd.to_numeric(\n",
    "    bib_search_screening['Publication Year'], errors='coerce'\n",
    ").astype('Int64')\n",
    "\n",
    "bib_search_screening['Study_ID'] = pd.to_numeric(\n",
    "    bib_search_screening['Study_ID'], errors='coerce'\n",
    ").astype('Int64')\n",
    "\n",
    "# Done — your DataFrame is now ready\n",
    "bib_search_screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "5861139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "export_path = os.path.join(output_path, 'bib_search_screen_start.csv')\n",
    "bib_search_screening.to_csv(export_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "09abae45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Full text not available in English.',\n",
       " 2: 'Studies not focusing on intentional self-ingestion (into the gastrointestinal tract) of foreign object via the oral cavity (mouth) or where unclear if ingested.',\n",
       " 3: 'Studies focussing solely on accidental ingestion.',\n",
       " 4: 'Non-Human/ animal studies.',\n",
       " 5: 'Reviews, editorials, commentaries, and opinion pieces without original empirical data.',\n",
       " 6: 'Duplicate publications or studies with overlapping data sets (the most comprehensive or recent study will be included).',\n",
       " 7: 'Studies focusing on ingestion or co-ingestion of substances (e.g. poisons, medications) rather than physical foreign objects.',\n",
       " 8: 'Ingestions undertaken in controlled environment as part of voluntary study.',\n",
       " 9: 'Ingestions not explicitly stated to be intentional and history not suggestive of deliberate ingestion (i.e. Age < 8, no history of previous ingestions, no psychiatric co-morbidities, not a prisoner/detainee/vulnerable group).',\n",
       " 10: 'Does not meet inclusion criteria.',\n",
       " 11: 'Ingestions where death resulted from other means (i.e. suicide)'}"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclusion_criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6cabfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc-dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
